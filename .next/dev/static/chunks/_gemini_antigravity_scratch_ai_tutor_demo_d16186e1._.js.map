{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jayesh_naphade/.gemini/antigravity/scratch/ai_tutor_demo/lib/gemini.ts"],"sourcesContent":["import { GoogleGenerativeAI } from \"@google/generative-ai\";\r\n\r\nexport interface ChatMessage {\r\n    role: \"user\" | \"model\";\r\n    parts: string;\r\n}\r\n\r\nexport const getGeminiResponse = async (\r\n    history: ChatMessage[],\r\n    message: string,\r\n    transcript: string\r\n) => {\r\n    const apiKey = process.env.NEXT_PUBLIC_GEMINI_API_KEY;\r\n    if (!apiKey) {\r\n        throw new Error(\"Gemini API Key is missing\");\r\n    }\r\n\r\n    const genAI = new GoogleGenerativeAI(apiKey);\r\n    const model = genAI.getGenerativeModel({ model: \"gemini-1.5-flash\" });\r\n\r\n    const systemPrompt = `You are an AI Tutor. You are helpful, friendly, and concise.\r\n  You have been provided with the following video transcript:\r\n  \"${transcript}\"\r\n  \r\n  CRITICAL INSTRUCTIONS:\r\n  1. Answer the user's questions based ONLY on the content of the transcript above.\r\n  2. If the answer is not in the transcript, politely say: \"I'm sorry, but that information isn't covered in this video.\"\r\n  3. Do not use outside knowledge.\r\n  4. Keep your responses conversational and suitable for a voice interface (avoid long lists or complex formatting unless necessary).\r\n  5. Your response will be spoken out loud, so use natural language.`;\r\n\r\n    const chat = model.startChat({\r\n        history: [\r\n            {\r\n                role: \"user\",\r\n                parts: [{ text: systemPrompt }],\r\n            },\r\n            {\r\n                role: \"model\",\r\n                parts: [{ text: \"Understood. I am ready to answer questions based strictly on the video transcript provided.\" }],\r\n            },\r\n            ...history.map((msg) => ({\r\n                role: msg.role,\r\n                parts: [{ text: msg.parts }],\r\n            })),\r\n        ],\r\n    });\r\n\r\n    const result = await chat.sendMessage(message);\r\n    const response = result.response;\r\n    return response.text();\r\n};\r\n"],"names":[],"mappings":";;;;AAYmB;AAZnB;;AAOO,MAAM,oBAAoB,OAC7B,SACA,SACA;IAEA,MAAM;IACN;;IAIA,MAAM,QAAQ,IAAI,8OAAkB,CAAC;IACrC,MAAM,QAAQ,MAAM,kBAAkB,CAAC;QAAE,OAAO;IAAmB;IAEnE,MAAM,eAAe,CAAC;;GAEvB,EAAE,WAAW;;;;;;;oEAOoD,CAAC;IAEjE,MAAM,OAAO,MAAM,SAAS,CAAC;QACzB,SAAS;YACL;gBACI,MAAM;gBACN,OAAO;oBAAC;wBAAE,MAAM;oBAAa;iBAAE;YACnC;YACA;gBACI,MAAM;gBACN,OAAO;oBAAC;wBAAE,MAAM;oBAA8F;iBAAE;YACpH;eACG,QAAQ,GAAG,CAAC,CAAC,MAAQ,CAAC;oBACrB,MAAM,IAAI,IAAI;oBACd,OAAO;wBAAC;4BAAE,MAAM,IAAI,KAAK;wBAAC;qBAAE;gBAChC,CAAC;SACJ;IACL;IAEA,MAAM,SAAS,MAAM,KAAK,WAAW,CAAC;IACtC,MAAM,WAAW,OAAO,QAAQ;IAChC,OAAO,SAAS,IAAI;AACxB"}},
    {"offset": {"line": 68, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jayesh_naphade/.gemini/antigravity/scratch/ai_tutor_demo/components/ChatInterface.tsx"],"sourcesContent":["\"use client\";\r\n\r\nimport { useState, useEffect, useRef } from \"react\";\r\nimport { motion } from \"framer-motion\";\r\nimport { Mic, Square, ArrowLeft, Volume2, Video } from \"lucide-react\";\r\nimport { getGeminiResponse, ChatMessage } from \"@/lib/gemini\";\r\nimport 'regenerator-runtime/runtime';\r\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\r\n\r\ninterface ChatInterfaceProps {\r\n    transcript: string;\r\n    videoUrl: string;\r\n    onBack: () => void;\r\n}\r\n\r\nexport default function ChatInterface({ transcript, videoUrl, onBack }: ChatInterfaceProps) {\r\n    const [history, setHistory] = useState<ChatMessage[]>([]);\r\n    const [isProcessing, setIsProcessing] = useState(false);\r\n    const [isPlaying, setIsPlaying] = useState(false);\r\n    const [status, setStatus] = useState<\"idle\" | \"listening\" | \"processing\" | \"speaking\">(\"idle\");\r\n\r\n    const {\r\n        transcript: userTranscript,\r\n        listening,\r\n        resetTranscript,\r\n        browserSupportsSpeechRecognition\r\n    } = useSpeechRecognition();\r\n\r\n    // Auto-send when user stops speaking (simple silence detection logic could be added, \r\n    // but for now we'll use a manual stop or a timeout if needed. \r\n    // Actually, let's use a manual \"Hold to Speak\" or \"Toggle\" for better control in a demo).\r\n    // Better yet: \"Toggle Mic\".\r\n\r\n    // Silence detection logic\r\n    const silenceTimer = useRef<NodeJS.Timeout | null>(null);\r\n\r\n    useEffect(() => {\r\n        if (status === \"listening\") {\r\n            // Clear existing timer on every update (speech detected)\r\n            if (silenceTimer.current) clearTimeout(silenceTimer.current);\r\n\r\n            // Set new timer: if no update for 2000ms, stop and send\r\n            silenceTimer.current = setTimeout(() => {\r\n                if (userTranscript.trim()) {\r\n                    SpeechRecognition.stopListening();\r\n                    handleSend(userTranscript);\r\n                }\r\n            }, 2000);\r\n        }\r\n\r\n        return () => {\r\n            if (silenceTimer.current) clearTimeout(silenceTimer.current);\r\n        };\r\n    }, [userTranscript, status]);\r\n\r\n    const handleMicToggle = () => {\r\n        if (listening) {\r\n            SpeechRecognition.stopListening();\r\n            // handleSend(userTranscript); // Don't send here, let silence detector or manual stop handle it? \r\n            // Actually if manual stop, we should send.\r\n            handleSend(userTranscript);\r\n        } else {\r\n            resetTranscript();\r\n            setStatus(\"listening\"); // Explicitly set status\r\n            SpeechRecognition.startListening({ continuous: true });\r\n        }\r\n    };\r\n\r\n    const handleSend = async (text: string) => {\r\n        if (!text.trim()) {\r\n            setStatus(\"idle\");\r\n            return;\r\n        }\r\n\r\n        setStatus(\"processing\");\r\n        const newHistory = [...history, { role: \"user\" as const, parts: text }];\r\n        setHistory(newHistory);\r\n\r\n        try {\r\n            const aiResponseText = await getGeminiResponse(newHistory, text, transcript);\r\n\r\n            const updatedHistory = [...newHistory, { role: \"model\" as const, parts: aiResponseText }];\r\n            setHistory(updatedHistory);\r\n\r\n            // Play TTS\r\n            await playTTS(aiResponseText);\r\n\r\n        } catch (error) {\r\n            console.error(\"Error getting response:\", error);\r\n            setStatus(\"idle\");\r\n        }\r\n    };\r\n\r\n    const playTTS = async (text: string) => {\r\n        setStatus(\"speaking\");\r\n        setIsPlaying(true);\r\n        try {\r\n            const res = await fetch(\"/api/tts\", {\r\n                method: \"POST\",\r\n                headers: { \"Content-Type\": \"application/json\" },\r\n                body: JSON.stringify({ text }),\r\n            });\r\n\r\n            const data = await res.json();\r\n            if (data.audioContent) {\r\n                const audio = new Audio(`data:audio/mp3;base64,${data.audioContent}`);\r\n                audio.onended = () => {\r\n                    setIsPlaying(false);\r\n                    setStatus(\"idle\");\r\n                };\r\n                await audio.play();\r\n            }\r\n        } catch (err) {\r\n            console.error(\"TTS Error:\", err);\r\n            setIsPlaying(false);\r\n            setStatus(\"idle\");\r\n        }\r\n    };\r\n\r\n    if (!browserSupportsSpeechRecognition) {\r\n        return <div>Browser does not support speech recognition. Please use Chrome.</div>;\r\n    }\r\n\r\n    return (\r\n        <motion.div\r\n            initial={{ opacity: 0 }}\r\n            animate={{ opacity: 1 }}\r\n            className=\"w-full flex flex-col h-[80vh] relative\"\r\n        >\r\n            {/* Header */}\r\n            <div className=\"flex items-center justify-between mb-8\">\r\n                <button\r\n                    onClick={onBack}\r\n                    className=\"p-2 hover:bg-slate-800 rounded-full transition-colors text-slate-400 hover:text-white\"\r\n                >\r\n                    <ArrowLeft className=\"w-6 h-6\" />\r\n                </button>\r\n                <div className=\"flex items-center space-x-2 text-sm text-slate-400 bg-slate-900/50 px-4 py-2 rounded-full border border-slate-800\">\r\n                    <Video className=\"w-4 h-4\" />\r\n                    <span className=\"max-w-[200px] truncate\">{videoUrl}</span>\r\n                </div>\r\n            </div>\r\n\r\n            {/* Main Visualizer Area */}\r\n            <div className=\"flex-1 flex flex-col items-center justify-center relative\">\r\n\r\n                {/* Status Text */}\r\n                <div className=\"absolute top-10 text-center space-y-2\">\r\n                    <h2 className=\"text-2xl font-medium text-slate-200\">\r\n                        {status === \"idle\" && \"Tap microphone to speak\"}\r\n                        {status === \"listening\" && \"Listening...\"}\r\n                        {status === \"processing\" && \"Thinking...\"}\r\n                        {status === \"speaking\" && \"AI Tutor Speaking...\"}\r\n                    </h2>\r\n                    {status === \"listening\" && (\r\n                        <p className=\"text-slate-500 text-lg max-w-2xl px-4\">{userTranscript}</p>\r\n                    )}\r\n                </div>\r\n\r\n                {/* Visualizer Circle */}\r\n                <div className=\"relative\">\r\n                    {/* Pulse Effect */}\r\n                    {(status === \"listening\" || status === \"speaking\") && (\r\n                        <>\r\n                            <motion.div\r\n                                animate={{ scale: [1, 1.5, 1], opacity: [0.5, 0, 0.5] }}\r\n                                transition={{ repeat: Infinity, duration: 2 }}\r\n                                className=\"absolute inset-0 bg-blue-500/30 rounded-full blur-xl\"\r\n                            />\r\n                            <motion.div\r\n                                animate={{ scale: [1, 1.2, 1], opacity: [0.8, 0, 0.8] }}\r\n                                transition={{ repeat: Infinity, duration: 1.5, delay: 0.5 }}\r\n                                className=\"absolute inset-0 bg-purple-500/30 rounded-full blur-xl\"\r\n                            />\r\n                        </>\r\n                    )}\r\n\r\n                    {/* Mic Button */}\r\n                    <button\r\n                        onClick={handleMicToggle}\r\n                        disabled={status === \"processing\" || status === \"speaking\"}\r\n                        className={`\r\n              relative z-10 w-32 h-32 rounded-full flex items-center justify-center transition-all duration-300\r\n              ${status === \"listening\" ? \"bg-red-500 shadow-[0_0_50px_rgba(239,68,68,0.5)]\" :\r\n                                status === \"processing\" ? \"bg-yellow-500 animate-pulse\" :\r\n                                    status === \"speaking\" ? \"bg-green-500 shadow-[0_0_50px_rgba(34,197,94,0.5)]\" :\r\n                                        \"bg-blue-600 hover:bg-blue-500 shadow-[0_0_30px_rgba(37,99,235,0.3)] hover:shadow-[0_0_50px_rgba(37,99,235,0.5)]\"\r\n                            }\r\n            `}\r\n                    >\r\n                        {status === \"listening\" ? (\r\n                            <Square className=\"w-12 h-12 text-white fill-current\" />\r\n                        ) : status === \"speaking\" ? (\r\n                            <Volume2 className=\"w-12 h-12 text-white\" />\r\n                        ) : (\r\n                            <Mic className=\"w-12 h-12 text-white\" />\r\n                        )}\r\n                    </button>\r\n                </div>\r\n            </div>\r\n\r\n            {/* Hidden Video Player (for reference/compliance, or we can show it small) */}\r\n            <div className=\"absolute bottom-0 right-0 w-64 opacity-50 hover:opacity-100 transition-opacity\">\r\n                {/* We can embed the YouTube player here if needed, but for voice demo it might be distracting. \r\n            Let's keep it hidden or very subtle. \r\n            Actually, the user might want to SEE the video. \r\n            Let's put it in a small box in the corner. */}\r\n                <div className=\"aspect-video bg-black rounded-lg overflow-hidden border border-slate-800\">\r\n                    <iframe\r\n                        width=\"100%\"\r\n                        height=\"100%\"\r\n                        src={`https://www.youtube.com/embed/${videoUrl.split('v=')[1]?.split('&')[0]}`}\r\n                        allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\"\r\n                        allowFullScreen\r\n                    />\r\n                </div>\r\n            </div>\r\n\r\n        </motion.div>\r\n    );\r\n}\r\n"],"names":[],"mappings":";;;;;AAEA;AACA;AACA;AAAA;AAAA;AAAA;AAAA;AACA;AACA;AACA;;;AAPA;;;;;;;AAee,SAAS,cAAc,EAAE,UAAU,EAAE,QAAQ,EAAE,MAAM,EAAsB;;IACtF,MAAM,CAAC,SAAS,WAAW,GAAG,IAAA,gOAAQ,EAAgB,EAAE;IACxD,MAAM,CAAC,cAAc,gBAAgB,GAAG,IAAA,gOAAQ,EAAC;IACjD,MAAM,CAAC,WAAW,aAAa,GAAG,IAAA,gOAAQ,EAAC;IAC3C,MAAM,CAAC,QAAQ,UAAU,GAAG,IAAA,gOAAQ,EAAmD;IAEvF,MAAM,EACF,YAAY,cAAc,EAC1B,SAAS,EACT,eAAe,EACf,gCAAgC,EACnC,GAAG,IAAA,iPAAoB;IAExB,sFAAsF;IACtF,+DAA+D;IAC/D,0FAA0F;IAC1F,4BAA4B;IAE5B,0BAA0B;IAC1B,MAAM,eAAe,IAAA,8NAAM,EAAwB;IAEnD,IAAA,iOAAS;mCAAC;YACN,IAAI,WAAW,aAAa;gBACxB,yDAAyD;gBACzD,IAAI,aAAa,OAAO,EAAE,aAAa,aAAa,OAAO;gBAE3D,wDAAwD;gBACxD,aAAa,OAAO,GAAG;+CAAW;wBAC9B,IAAI,eAAe,IAAI,IAAI;4BACvB,oOAAiB,CAAC,aAAa;4BAC/B,WAAW;wBACf;oBACJ;8CAAG;YACP;YAEA;2CAAO;oBACH,IAAI,aAAa,OAAO,EAAE,aAAa,aAAa,OAAO;gBAC/D;;QACJ;kCAAG;QAAC;QAAgB;KAAO;IAE3B,MAAM,kBAAkB;QACpB,IAAI,WAAW;YACX,oOAAiB,CAAC,aAAa;YAC/B,kGAAkG;YAClG,2CAA2C;YAC3C,WAAW;QACf,OAAO;YACH;YACA,UAAU,cAAc,wBAAwB;YAChD,oOAAiB,CAAC,cAAc,CAAC;gBAAE,YAAY;YAAK;QACxD;IACJ;IAEA,MAAM,aAAa,OAAO;QACtB,IAAI,CAAC,KAAK,IAAI,IAAI;YACd,UAAU;YACV;QACJ;QAEA,UAAU;QACV,MAAM,aAAa;eAAI;YAAS;gBAAE,MAAM;gBAAiB,OAAO;YAAK;SAAE;QACvE,WAAW;QAEX,IAAI;YACA,MAAM,iBAAiB,MAAM,IAAA,4LAAiB,EAAC,YAAY,MAAM;YAEjE,MAAM,iBAAiB;mBAAI;gBAAY;oBAAE,MAAM;oBAAkB,OAAO;gBAAe;aAAE;YACzF,WAAW;YAEX,WAAW;YACX,MAAM,QAAQ;QAElB,EAAE,OAAO,OAAO;YACZ,QAAQ,KAAK,CAAC,2BAA2B;YACzC,UAAU;QACd;IACJ;IAEA,MAAM,UAAU,OAAO;QACnB,UAAU;QACV,aAAa;QACb,IAAI;YACA,MAAM,MAAM,MAAM,MAAM,YAAY;gBAChC,QAAQ;gBACR,SAAS;oBAAE,gBAAgB;gBAAmB;gBAC9C,MAAM,KAAK,SAAS,CAAC;oBAAE;gBAAK;YAChC;YAEA,MAAM,OAAO,MAAM,IAAI,IAAI;YAC3B,IAAI,KAAK,YAAY,EAAE;gBACnB,MAAM,QAAQ,IAAI,MAAM,CAAC,sBAAsB,EAAE,KAAK,YAAY,EAAE;gBACpE,MAAM,OAAO,GAAG;oBACZ,aAAa;oBACb,UAAU;gBACd;gBACA,MAAM,MAAM,IAAI;YACpB;QACJ,EAAE,OAAO,KAAK;YACV,QAAQ,KAAK,CAAC,cAAc;YAC5B,aAAa;YACb,UAAU;QACd;IACJ;IAEA,IAAI,CAAC,kCAAkC;QACnC,qBAAO,oPAAC;sBAAI;;;;;;IAChB;IAEA,qBACI,oPAAC,8PAAM,CAAC,GAAG;QACP,SAAS;YAAE,SAAS;QAAE;QACtB,SAAS;YAAE,SAAS;QAAE;QACtB,WAAU;;0BAGV,oPAAC;gBAAI,WAAU;;kCACX,oPAAC;wBACG,SAAS;wBACT,WAAU;kCAEV,cAAA,oPAAC,uRAAS;4BAAC,WAAU;;;;;;;;;;;kCAEzB,oPAAC;wBAAI,WAAU;;0CACX,oPAAC,uQAAK;gCAAC,WAAU;;;;;;0CACjB,oPAAC;gCAAK,WAAU;0CAA0B;;;;;;;;;;;;;;;;;;0BAKlD,oPAAC;gBAAI,WAAU;;kCAGX,oPAAC;wBAAI,WAAU;;0CACX,oPAAC;gCAAG,WAAU;;oCACT,WAAW,UAAU;oCACrB,WAAW,eAAe;oCAC1B,WAAW,gBAAgB;oCAC3B,WAAW,cAAc;;;;;;;4BAE7B,WAAW,6BACR,oPAAC;gCAAE,WAAU;0CAAyC;;;;;;;;;;;;kCAK9D,oPAAC;wBAAI,WAAU;;4BAEV,CAAC,WAAW,eAAe,WAAW,UAAU,mBAC7C;;kDACI,oPAAC,8PAAM,CAAC,GAAG;wCACP,SAAS;4CAAE,OAAO;gDAAC;gDAAG;gDAAK;6CAAE;4CAAE,SAAS;gDAAC;gDAAK;gDAAG;6CAAI;wCAAC;wCACtD,YAAY;4CAAE,QAAQ;4CAAU,UAAU;wCAAE;wCAC5C,WAAU;;;;;;kDAEd,oPAAC,8PAAM,CAAC,GAAG;wCACP,SAAS;4CAAE,OAAO;gDAAC;gDAAG;gDAAK;6CAAE;4CAAE,SAAS;gDAAC;gDAAK;gDAAG;6CAAI;wCAAC;wCACtD,YAAY;4CAAE,QAAQ;4CAAU,UAAU;4CAAK,OAAO;wCAAI;wCAC1D,WAAU;;;;;;;;0CAMtB,oPAAC;gCACG,SAAS;gCACT,UAAU,WAAW,gBAAgB,WAAW;gCAChD,WAAW,CAAC;;cAEtB,EAAE,WAAW,cAAc,qDACT,WAAW,eAAe,gCACtB,WAAW,aAAa,uDACpB,kHACX;YACjB,CAAC;0CAEY,WAAW,4BACR,oPAAC,0QAAM;oCAAC,WAAU;;;;;2CAClB,WAAW,2BACX,oPAAC,iRAAO;oCAAC,WAAU;;;;;yDAEnB,oPAAC,iQAAG;oCAAC,WAAU;;;;;;;;;;;;;;;;;;;;;;;0BAO/B,oPAAC;gBAAI,WAAU;0BAKX,cAAA,oPAAC;oBAAI,WAAU;8BACX,cAAA,oPAAC;wBACG,OAAM;wBACN,QAAO;wBACP,KAAK,CAAC,8BAA8B,EAAE,SAAS,KAAK,CAAC,KAAK,CAAC,EAAE,EAAE,MAAM,IAAI,CAAC,EAAE,EAAE;wBAC9E,OAAM;wBACN,eAAe;;;;;;;;;;;;;;;;;;;;;;AAOvC;GA7MwB;;QAWhB,iPAAoB;;;KAXJ"}},
    {"offset": {"line": 446, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jayesh_naphade/.gemini/antigravity/scratch/ai_tutor_demo/app/page.tsx"],"sourcesContent":["\"use client\";\n\nimport { useState, useEffect, useRef } from \"react\";\nimport { motion, AnimatePresence } from \"framer-motion\";\nimport { Mic, MicOff, Play, Loader2, Volume2 } from \"lucide-react\";\nimport ChatInterface from \"@/components/ChatInterface\";\n\nexport default function Home() {\n  const [videoUrl, setVideoUrl] = useState(\"\");\n  const [transcript, setTranscript] = useState(\"\");\n  const [isLoading, setIsLoading] = useState(false);\n  const [isChatActive, setIsChatActive] = useState(false);\n  const [error, setError] = useState(\"\");\n\n  const handleStart = async () => {\n    if (!videoUrl) return;\n    setIsLoading(true);\n    setError(\"\");\n\n    try {\n      const res = await fetch(\"/api/transcript\", {\n        method: \"POST\",\n        headers: { \"Content-Type\": \"application/json\" },\n        body: JSON.stringify({ url: videoUrl }),\n      });\n\n      const data = await res.json();\n\n      if (!res.ok) {\n        throw new Error(data.error || \"Failed to fetch transcript\");\n      }\n\n      setTranscript(data.transcript);\n      setIsChatActive(true);\n    } catch (err: any) {\n      setError(err.message);\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  return (\n    <main className=\"min-h-screen bg-slate-950 text-slate-100 flex flex-col items-center justify-center p-4 overflow-hidden relative\">\n      {/* Background Gradients */}\n      <div className=\"absolute top-0 left-0 w-full h-full overflow-hidden z-0 pointer-events-none\">\n        <div className=\"absolute top-[-10%] left-[-10%] w-[40%] h-[40%] bg-purple-600/20 rounded-full blur-[100px]\" />\n        <div className=\"absolute bottom-[-10%] right-[-10%] w-[40%] h-[40%] bg-blue-600/20 rounded-full blur-[100px]\" />\n      </div>\n\n      <div className=\"z-10 w-full max-w-4xl\">\n        <AnimatePresence mode=\"wait\">\n          {!isChatActive ? (\n            <motion.div\n              key=\"landing\"\n              initial={{ opacity: 0, y: 20 }}\n              animate={{ opacity: 1, y: 0 }}\n              exit={{ opacity: 0, y: -20 }}\n              className=\"flex flex-col items-center text-center space-y-8\"\n            >\n              <div className=\"space-y-4\">\n                <h1 className=\"text-5xl md:text-7xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-400\">\n                  AI Video Tutor\n                </h1>\n                <p className=\"text-xl text-slate-400 max-w-2xl mx-auto\">\n                  Have a live voice conversation with any YouTube video.\n                  <br />\n                  Just paste the link and start learning.\n                </p>\n              </div>\n\n              <div className=\"w-full max-w-xl space-y-4\">\n                <div className=\"relative group\">\n                  <div className=\"absolute -inset-0.5 bg-gradient-to-r from-blue-500 to-purple-600 rounded-lg blur opacity-75 group-hover:opacity-100 transition duration-1000 group-hover:duration-200\" />\n                  <input\n                    type=\"text\"\n                    placeholder=\"Paste YouTube URL here...\"\n                    value={videoUrl}\n                    onChange={(e) => setVideoUrl(e.target.value)}\n                    className=\"relative w-full bg-slate-900 border border-slate-700 text-white placeholder-slate-500 rounded-lg px-6 py-4 focus:outline-none focus:ring-2 focus:ring-blue-500/50 text-lg\"\n                  />\n                </div>\n\n                <div className=\"flex justify-center\">\n                  <button\n                    onClick={() => setVideoUrl(\"https://www.youtube.com/watch?v=LXb3EKWsInQ\")}\n                    className=\"text-sm text-slate-500 hover:text-blue-400 transition-colors underline\"\n                  >\n                    Try a Demo Video (Redux Tutorial)\n                  </button>\n                </div>\n\n                {error && (\n                  <p className=\"text-red-400 text-sm\">{error}</p>\n                )}\n\n                <button\n                  onClick={handleStart}\n                  disabled={isLoading || !videoUrl}\n                  className=\"w-full bg-white text-slate-900 font-bold py-4 rounded-lg hover:bg-slate-100 transition-colors disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center space-x-2\"\n                >\n                  {isLoading ? (\n                    <>\n                      <Loader2 className=\"animate-spin\" />\n                      <span>Processing Video...</span>\n                    </>\n                  ) : (\n                    <>\n                      <Play className=\"w-5 h-5 fill-current\" />\n                      <span>Start Session</span>\n                    </>\n                  )}\n                </button>\n              </div>\n            </motion.div>\n          ) : (\n            <ChatInterface\n              transcript={transcript}\n              videoUrl={videoUrl}\n              onBack={() => setIsChatActive(false)}\n            />\n          )}\n        </AnimatePresence>\n      </div>\n    </main>\n  );\n}\n"],"names":[],"mappings":";;;;;AAEA;AACA;AAAA;AACA;AAAA;AACA;;;AALA;;;;;AAOe,SAAS;;IACtB,MAAM,CAAC,UAAU,YAAY,GAAG,IAAA,gOAAQ,EAAC;IACzC,MAAM,CAAC,YAAY,cAAc,GAAG,IAAA,gOAAQ,EAAC;IAC7C,MAAM,CAAC,WAAW,aAAa,GAAG,IAAA,gOAAQ,EAAC;IAC3C,MAAM,CAAC,cAAc,gBAAgB,GAAG,IAAA,gOAAQ,EAAC;IACjD,MAAM,CAAC,OAAO,SAAS,GAAG,IAAA,gOAAQ,EAAC;IAEnC,MAAM,cAAc;QAClB,IAAI,CAAC,UAAU;QACf,aAAa;QACb,SAAS;QAET,IAAI;YACF,MAAM,MAAM,MAAM,MAAM,mBAAmB;gBACzC,QAAQ;gBACR,SAAS;oBAAE,gBAAgB;gBAAmB;gBAC9C,MAAM,KAAK,SAAS,CAAC;oBAAE,KAAK;gBAAS;YACvC;YAEA,MAAM,OAAO,MAAM,IAAI,IAAI;YAE3B,IAAI,CAAC,IAAI,EAAE,EAAE;gBACX,MAAM,IAAI,MAAM,KAAK,KAAK,IAAI;YAChC;YAEA,cAAc,KAAK,UAAU;YAC7B,gBAAgB;QAClB,EAAE,OAAO,KAAU;YACjB,SAAS,IAAI,OAAO;QACtB,SAAU;YACR,aAAa;QACf;IACF;IAEA,qBACE,oPAAC;QAAK,WAAU;;0BAEd,oPAAC;gBAAI,WAAU;;kCACb,oPAAC;wBAAI,WAAU;;;;;;kCACf,oPAAC;wBAAI,WAAU;;;;;;;;;;;;0BAGjB,oPAAC;gBAAI,WAAU;0BACb,cAAA,oPAAC,sQAAe;oBAAC,MAAK;8BACnB,CAAC,6BACA,oPAAC,8PAAM,CAAC,GAAG;wBAET,SAAS;4BAAE,SAAS;4BAAG,GAAG;wBAAG;wBAC7B,SAAS;4BAAE,SAAS;4BAAG,GAAG;wBAAE;wBAC5B,MAAM;4BAAE,SAAS;4BAAG,GAAG,CAAC;wBAAG;wBAC3B,WAAU;;0CAEV,oPAAC;gCAAI,WAAU;;kDACb,oPAAC;wCAAG,WAAU;kDAA4G;;;;;;kDAG1H,oPAAC;wCAAE,WAAU;;4CAA2C;0DAEtD,oPAAC;;;;;4CAAK;;;;;;;;;;;;;0CAKV,oPAAC;gCAAI,WAAU;;kDACb,oPAAC;wCAAI,WAAU;;0DACb,oPAAC;gDAAI,WAAU;;;;;;0DACf,oPAAC;gDACC,MAAK;gDACL,aAAY;gDACZ,OAAO;gDACP,UAAU,CAAC,IAAM,YAAY,EAAE,MAAM,CAAC,KAAK;gDAC3C,WAAU;;;;;;;;;;;;kDAId,oPAAC;wCAAI,WAAU;kDACb,cAAA,oPAAC;4CACC,SAAS,IAAM,YAAY;4CAC3B,WAAU;sDACX;;;;;;;;;;;oCAKF,uBACC,oPAAC;wCAAE,WAAU;kDAAwB;;;;;;kDAGvC,oPAAC;wCACC,SAAS;wCACT,UAAU,aAAa,CAAC;wCACxB,WAAU;kDAET,0BACC;;8DACE,oPAAC,sRAAO;oDAAC,WAAU;;;;;;8DACnB,oPAAC;8DAAK;;;;;;;yEAGR;;8DACE,oPAAC,oQAAI;oDAAC,WAAU;;;;;;8DAChB,oPAAC;8DAAK;;;;;;;;;;;;;;;;;;;;uBAvDV;;;;6CA8DN,oPAAC,iMAAa;wBACZ,YAAY;wBACZ,UAAU;wBACV,QAAQ,IAAM,gBAAgB;;;;;;;;;;;;;;;;;;;;;;AAO5C;GAtHwB;KAAA"}}]
}